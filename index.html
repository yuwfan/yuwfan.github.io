<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Yuwei Fang</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="https://yuwfan.github.io/" />
	    <meta property="og:title" content="Yuwei Fang" />
	    <meta property="og:image" content="https://yuwfan.github.io/blob/master/img/yuwfan.jpeg" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Yuwei Fang">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col-lg-3 col-md-4">
                    <img class="img-fluid rounded" src="img/yuwfan.jpeg" alt="Yuwei Fang">
                    <p>
                        <i class="fa fa-envelope pt-3"></i> studyfang AT gmail.com
                    </br>
                        <i class="fa fa-building"></i> Redmond, Washington
                    </p>
                </div>
                <div class="col-lg-9 col-md-8">
                    <h1>Yuwei Fang</h1>
                    <p>
                        I am a Senior Applied Scientist from <a href="https://www.microsoft.com/en-us/research/group/knowledge-and-language/" target="_blank">Knowledge and Language Team</a> under
                        <a href="https://www.microsoft.com/en-us/research/group/cognitive-services-research/" target=""_blank> Azure Cognitive Services Research Group</a> at Microsoft.
                        Prior to Microsoft, I received the master degree in computer science from Peking University.
                        My research interests are in Natural language processing and Machine Learning.
                        I am particularly interested in how to build an unified system that can ground and reason on diversified external world knowledge, to realize multilingual human machine communication.
                        My recent work has focused on
                        <div class="row">
                            <div class="col">
                            <ul>
                                <li>
                                    Knowledge-based Language Learning
                                    (<a href="https://arxiv.org/abs/2110.08462" target="_blank">Fang et al., ACL 2022</a>;
                                    <a href="https://arxiv.org/abs/2110.04330" target="_blank">Yu et al., ACL 2022</a>;
                                    <a href="https://arxiv.org/abs/2203.08773" target="_blank">Wang et al., ACL 2022</a>;
                                    <a href="https://arxiv.org/abs/2110.06490" target="_blank">Yu et al., ACL 2022</a>;
                                </li>
                                <li>
                                    Multi-lingual or multi-modal representation learning(
                                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17512" target="_blank">Fang et al., AAAI 2021</a>;
                                    <a href="https://arxiv.org/abs/2205.01818" target="_blank">Yang et al., AAAI 2023</a>)
                                    
                                </li>
                                <li>
                                    Question Answering(
                                        <a href="https://arxiv.org/abs/1911.03631" target="_blank">Fang et al., EMNLP 2020</a>;
                                        <a href="https://arxiv.org/abs/2009.06097" target="_blank">Wang et al. ACL 2021</a>
                                    )
                                </li>
                            </ul>
                            </div>
                        </div>
                    </p>
                    <p>
                        <!-- [<a href="files/CV_Yuwei_Fang.pdf" target="_blank">Full CV</a>] -->
                        [<a href="https://scholar.google.com/citations?user=Om_-hHsAAAAJ&hl=en" target="_blank">Google Scholar</a>]
                        [<a href="https://www.linkedin.com/in/yuwei-fang-79220192/" target="_blank">LinkedIn</a>]
                        [<a href="https://github.com/yuwfan/" target="_blank">Github</a>]
                        [<a href="https://twitter.com/studyfang_" target="_blank">Twitter</a>]
                    </p>
                </div>
            </div>

            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Publications</h2>
                    <ul class="pl">
			<li>
                            <b>i-Code: An Integrative and Composable Multimodal Learning Framework</b>
                            <br/>
                            Ziyi Yang*, <b>Yuwei Fang*</b>, Chenguang Zhu, et al.
                            <br/>
                            In <a href="https://aaai.org/Conferences/AAAI-23/" target="_blank">
                                <b>Proc. American Association of Artificial Intelligence (AAAI)  </b></a>, 2023.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2205.01818.pdf" target="">PDF</a>]
                        </li>
			<li>
                            <b>Retrieval Augmentation for Commonsense Reasoning: A Unified Approach</b>
                            <br/>
                            Wenhao Yu, Chenguang Zhu, Zhihan Zhang, Shuohang Wang, Zhuosheng Zhang, <b>Yuwei Fang</b>, Meng Jiang
                            <br/>
                            In <a href="https://2022.emnlp.org/" target="_blank">
                                <b>Conf. on Empirical Methods in Natural Language Processing (EMNLP) </b></a>, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2210.12887.pdf" target="">PDF</a>]
                            [<a href="https://github.com/wyu97/RACo" target="">Code</a>]
                            [<a href="https://www.cs.utexas.edu/~yasumasa/creak/leaderboard.html" target="">Leaderboard</a>]
                        </li>
			<li>
                            <b>Task Compass: Scaling Multi-task Pre-training with Task Prefix</b>
                            <br/>
                            Zhuosheng Zhang, Shuohang Wang, Yichong Xu, <b>Yuwei Fang</b>, Wenhao Yu, Yang Liu, Hai Zhao, Chenguang Zhu, Michael Zeng
                            <br/>
                            In <a href="https://2022.emnlp.org/" target="_blank">
                                <b>Findings of Conf. on Empirical Methods in Natural Language Processing (EMNLP) </b></a>, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2210.06277.pdf" target="">PDF</a>]
                        </li>
                        <li>
                            <b>Leveraging Knowledge in Multilingual Commonsense Reasoning</b>
                            <br/>
                            <b>Yuwei Fang</b>, Shuohang Wang, Yichong Xu, Ruochen Xu, Siqi Sun, Chenguang Zhu, Michael Zeng
                            <br/>
                            In <a href="https://www.2022.aclweb.org/" target="_blank">
                                <b>Findings of Association for Computational Linguistics (Findings of ACL) </b></a>, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2110.08462.pdf" target="">PDF</a>]
                            [<a href="https://inklab.usc.edu//XCSR/leaderboard" target="">Leaderboard</a>]
                        </li>
                        <li>
                            <b>Training data is more valuable than you think: A simple and effective method by retrieving from training data</b>
                            <br/>
                            Shuohang Wang, Yichong Xu, <b>Yuwei Fang</b>, Yang Liu, Siqi Sun, Ruochen Xu, Chenguang Zhu, Michael Zeng
                            <br/>
                            In <a href="https://www.2022.aclweb.org/" target="_blank">
                                <b>Association for Computational Linguistics (ACL) </b></a>, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2203.08773.pdf" target="">PDF</a>]
                            [<a href="https://github.com/microsoft/REINA" target="">Code</a>]
                        
                        </li>
                        <li>
                            <b>KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering</b>
                            <br/>
                            Donghan Yu, Chenguang Zhu, <b>Yuwei Fang</b>, Wenhao Yu, Shuohang Wang, Yichong Xu, Xiang Ren, Yiming Yang, Michael Zeng
                            <br/>
                            In <a href="https://www.2022.aclweb.org/" target="_blank">
                                <b>Association for Computational Linguistics (ACL) </b></a>, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2110.04330.pdf" target="">PDF</a>]
                        </li>
                        <li>
                            <b>Dict-BERT: Enhancing Language Model Pre-training with Dictionary</b>
                            <br/>
                            Wenhao Yu, Chenguang Zhu, <b>Yuwei Fang</b>, Donghan Yu, Shuohang Wang, Yichong Xu, Michael Zeng, Meng Jiang
                            <br/>
                            In <a href="https://www.2022.aclweb.org/" target="_blank">
                                <b>Findings of Association for Computational Linguistics (Findings of ACL) </b></a>, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2110.06490.pdf" target="">PDF</a>]
                            [<a href="https://github.com/wyu97/DictBERT" target="">Code</a>]
                        </li>
                        <li>
                            <b>RetGen: A Joint framework for Retrieval and Grounded Text Generation Modeling</b>
                            <br/>
                            Yizhe Zhang, Siqi Sun, Xiang Gao, <b>Yuwei Fang</b>, Chris Brockett, Michel Galley, Jianfeng Gao, Bill Dolan
                            <br/>
                            In <a href="https://aaai.org/Conferences/AAAI-22/" target="_blank">
                                <b>Proc. American Association of Artificial Intelligence (AAAI) </b></a>, 2022.
                            <br/>
                            [<a href="https://www.aaai.org/AAAI22Papers/AAAI-6144.ZhangY.pdf" target="">PDF</a>]
                            [<a href="https://github.com/dreasysnail/RetGen" target="">Code</a>]
                        </li>
                        <li>
                            <b>FILTER: An enhanced fusion method for cross-lingual language understanding</b>
                            <br/>
                            <b>Yuwei Fang*</b>, Shuohang Wang*, Zhe Gan, Siqi Sun, Jingjing Liu<br/>
                            In <a href="https://aaai.org/Conferences/AAAI-21/" target="_blank">
                                <b>Proc. American Association of Artificial Intelligence (AAAI) </b></a>, 2021.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2009.05166.pdf" target="">PDF</a>]
                            [<a href="https://github.com/yuwfan/FILTER" target="">Code</a>]
                            [<a href="https://sites.research.google/xtreme" target="">Leaderboard</a>]
                        </li>
                        <li>
                            <b>LightningDOT: Pre-training Visual-Semantic Embeddings for Real-Time Image-Text Retrieval</b>
                            <br/>
                            Siqi Sun, Yen-Chun Chen, Linjie Li, Shuohang Wang, <b>Yuwei Fang</b>, Jingjing Liu
                            <br/>
                            In <a href="https://2021.naacl.org/" target="_blank">
                                <b>Conf. on North American Chapter of the Association for Computational Linguistics (NAACL) </b></a>, 2021.
                            <br/>
                            [<a href="https://aclanthology.org/2021.naacl-main.77.pdf" target="">PDF</a>]
                            [<a href="https://github.com/intersun/LightningDOT" target="">Code</a>]
                        </li>
                        <li>
                            <b>Cluster-former: Clustering-based sparse transformer for long-range dependency encoding</b>
                            <br/>
                            Shuohang Wang, Luowei Zhou, Zhe Gan, Yen-Chun Chen, <b>Yuwei Fang</b>, Siqi Sun, Yu Cheng, Jingjing Liu
                            <br/>
                            In <a href="https://2021.aclweb.org/" target="_blank">
                                <b>Findings of Association for Computational Linguistics (Findings of ACL) </b></a>, 2021.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2009.06097.pdf" target="">PDF</a>]
                            [<a href="https://ai.google.com/research/NaturalQuestions/leaderboard" target="">Leaderboard</a>]
                        </li>
                        <li>
                            <b>Hierarchical graph network for multi-hop question answering</b>
                            <br/>
                            <b>Yuwei Fang</b>, Siqi Sun, Zhe Gan, Rohit Pillai, Shuohang Wang, Jingjing Liu
                            <br/>
                            In <a href="https://2020.emnlp.org/" target="_blank">
                                <b>Conf. on Empirical Methods in Natural Language Processing (EMNLP) </b></a>, 2020.
                            <br/>
                            [<a href="https://arxiv.org/pdf/1911.03631.pdf" target="">PDF</a>]
                            [<a href="https://github.com/yuwfan/HGN" target="">Code</a>]
                            [<a href="https://hotpotqa.github.io/" target="">Leaderboard</a>]
                        </li>
                        <li>
                            <b>Cross-Thought for Sentence Encoder Pre-training</b>
                            <br/>
                            Shuohang Wang, <b>Yuwei Fang</b>, Siqi Sun, Zhe Gan, Yu Cheng, Jing Jiang, Jingjing Liu
                            <br/>
                            In <a href="https://2020.emnlp.org/" target="_blank">
                                <b>Conf. on Empirical Methods in Natural Language Processing (EMNLP) </b></a>, 2020.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2010.03652.pdf" target="">PDF</a>]
                            [<a href="https://github.com/shuohangwang/Cross-Thought" target="">Code</a>]
                        </li>

                        <li>
                            <b>Contrastive Distillation on Intermediate Representations for Language Model Compression</b>
                            <br/>
                            Siqi Sun, Zhe Gan, Yu Cheng, <b>Yuwei Fang</b>, Shuohang Wang, Jingjing Liu
                            <br/>
                            In <a href="https://2020.emnlp.org/" target="_blank">
                                <b>Conf. on Empirical Methods in Natural Language Processing (EMNLP) </b></a>, 2020.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2009.14167.pdf" target="">PDF</a>]
                            [<a href="https://github.com/intersun/CoDIR" target="">Code</a>]
                            
                        </li>
                        
                        <!-- <li>
                            <b>i-Code: An Integrative and Composable Multimodal Learning Framework</b>
                            <br/>
                            Ziyi Yang*, <b>Yuwei Fang*</b>, Chenguang Zhu, Reid Pryzant, Dongdong Chen, Yu Shi, Yichong Xu, Yao Qian, Mei Gao, Yi-Ling Chen, Liyang Lu, Yujia Xie, Robert Gmyr, Noel Codella, Naoyuki Kanda, Bin Xiao, Yuan Lu, Takuya Yoshioka, Michael Zeng, Xuedong Huang
                            <br/>
                            Arxiv, 2022.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2205.01818.pdf" target="">PDF</a>]
                        </li>
                        <li>
                            <b>Does Knowledge Help General NLU? An Empirical Study</b>
                            <br/>
                            Ruochen Xu*, <b>Yuwei Fang*</b>Yuwei Fang, Chenguang Zhu, Michael Zeng<br/>
                            Arxiv, 2022.
                            <br/>
                            [<a href="" target="">PDF</a>]
                        </li>
                        <li>
                            <b>Accelerating Real-Time Question Answering via Question Generation</b>
                            <br/>
                            <b>Yuwei Fang</b>, Shuohang Wang, Zhe Gan, Siqi Sun, Jingjing Liu
                            <br/>
                            Arxiv, 2020.
                            <br/>
                            [<a href="https://arxiv.org/pdf/2009.05167.pdf" target="">PDF</a>]
                        </li>
                        <li>
                            <b>Stochastic answer networks for squad 2.0</b>
                            <br/>
                            Xiaodong Liu, Wei Li, <b>Yuwei Fang</b>, Aerin Kim, Kevin Duh, Jianfeng Gao
                            <br/>
                            Arxiv, 2022.
                            <br/>
                            [<a href="" target="">PDF</a>]
                        </li> -->
                        
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellany</h2>
                    <ul>
                        <li>
                            In my free time, I like staying with my family and outside activities.
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </body>
</html>
